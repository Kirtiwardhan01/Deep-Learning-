{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+oIDu12Xb70byhSvSfiXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirtiwardhan01/Deep-Learning-/blob/master/Tensorflow%20HandsOn%20-.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWegeCtebm-1",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow HandsOn on Boston Houseprice Dataset\n",
        "\n",
        "Version of Tensorflow used is 1.15\n",
        "\n",
        "**Building a Linear Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEplYaydEmYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "0ae632b3-fc3b-41e5-ee2f-7e1b8d9d4fc8"
      },
      "source": [
        "#Importing tensorflow and numpy \n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtRoABrsEqA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clears the default graph stack and resets the global default graph.\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWObP7XidFP8",
        "colab_type": "text"
      },
      "source": [
        "## Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzNc6Yp-GmYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd0f58f7-3aaa-4cbd-ecc2-4bb4945ada2f"
      },
      "source": [
        "#Importing the preloaded boston dataset from datasets\n",
        "from tensorflow.contrib.learn import datasets\n",
        "\n",
        "boston = datasets.load_dataset('boston')\n",
        "boston"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(data=array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]]), target=array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgtaQIdTJk9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d5812325-4b8e-427f-e3e9-c5a286e53d5c"
      },
      "source": [
        "#Below is the features that we feed to train the neural network\n",
        "boston.data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_XY7k-QOPbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "99865527-ab2b-4a4f-cdd6-a81c9f8fd4a8"
      },
      "source": [
        "#Target is our label (In this case it's continous variable output)\n",
        "oston.target"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvyQ19lcdQli",
        "colab_type": "text"
      },
      "source": [
        "## Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRMbIuKeOXPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting the features and target into array to represnt \n",
        "\n",
        "features = np.array(boston.data)\n",
        "\n",
        "prices = np.array(boston.target)\n",
        "prices = np.reshape(prices,[-1,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_VPV75qO8y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0c595981-0229-4279-a832-a23af8000a5f"
      },
      "source": [
        "#Let's check the shape of features and prices\n",
        "print(features.shape)\n",
        "print(prices.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n",
            "(506, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC3hEkL0difA",
        "colab_type": "text"
      },
      "source": [
        "## Building the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bQ6zkDlPHYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the input placeholders\n",
        "\n",
        "#Input features\n",
        "x = tf.placeholder(shape=[None,13],dtype=tf.float32,name='x-input')\n",
        "\n",
        "#Actual Output\n",
        "y_ = tf.placeholder(shape=[None,1],dtype=tf.float32,name='y-input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3moNsxQCP2FU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e7ea1f6-a962-4272-962e-78bfbad977dd"
      },
      "source": [
        "#Normalize the data\n",
        "x_nn = tf.nn.l2_normalize(x,axis=1)\n",
        "x_nn"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'l2_normalize_2:0' shape=(?, 13) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNsWmOy2QVhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the Weights and Bias\n",
        "\n",
        "W = tf.Variable(tf.zeros(shape=[13,1]),name='Weights')\n",
        "\n",
        "b = tf.Variable(tf.zeros(shape=[1]),name='Bias')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM0n7I01dwFc",
        "colab_type": "text"
      },
      "source": [
        "**Prediction - make sure to use normalized input features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfcsEjIzQ6k4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prediction\n",
        "y = tf.add(tf.matmul(x_nn,W),b,name='Output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbW1_BV1d594",
        "colab_type": "text"
      },
      "source": [
        "**Loss (Cost) Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhBY5KVRPdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Computing the loss\n",
        "loss = tf.reduce_mean(tf.square(y-y_),name='loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfoj5gQCeEpR",
        "colab_type": "text"
      },
      "source": [
        "**GradientDescent Optimizer to minimize Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liQ6K8fORktK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the model to optimise the loss\n",
        "\n",
        "train_op = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1j3n1yReNcl",
        "colab_type": "text"
      },
      "source": [
        "## Executing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCBDGZPsR-_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d0b7f43-c945-4022-ea72-1eb658d4a748"
      },
      "source": [
        "#Lets start graph Execution\n",
        "with tf.Session() as sess:\n",
        "    # variables need to be initialized before we can use them\n",
        "    # now is when the actual loading of variables will happen ---> lazy Loading \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    #how many times data need to be shown to model\n",
        "    training_epochs = 100000 \n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        #Calculate train_op and loss\n",
        "  \n",
        "        # this is where you loss calculation and optimization will start happening \n",
        "        train_model, train_loss = sess.run([train_op,loss],feed_dict={x:features, y_:prices})\n",
        "        \n",
        "        if epoch % 1000 == 0:\n",
        "            print ('Training loss at step: ', epoch, ' is ', train_loss)\n",
        "            print (sess.run([W,b]))\n",
        "            # put loss, W, b in Dictionary "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0  is  592.1469\n",
            "[array([[7.2091222e-02],\n",
            "       [6.7363268e-01],\n",
            "       [3.8339731e-01],\n",
            "       [3.6395455e-03],\n",
            "       [2.2200951e-02],\n",
            "       [2.7616996e-01],\n",
            "       [2.6348555e+00],\n",
            "       [1.7608340e-01],\n",
            "       [3.0071831e-01],\n",
            "       [1.4883699e+01],\n",
            "       [7.5592571e-01],\n",
            "       [1.5748419e+01],\n",
            "       [4.2662463e-01]], dtype=float32), array([22.532808], dtype=float32)]\n",
            "Training loss at step:  1000  is  55.015064\n",
            "[array([[-1.0082277e+01],\n",
            "       [ 3.4577881e+01],\n",
            "       [-1.0460780e+01],\n",
            "       [ 6.2690878e-01],\n",
            "       [ 2.6188219e-02],\n",
            "       [ 7.5701308e+00],\n",
            "       [-7.3193116e+00],\n",
            "       [-2.9694765e+00],\n",
            "       [ 4.0688562e+00],\n",
            "       [-1.2262685e+01],\n",
            "       [-8.1474113e+00],\n",
            "       [ 9.4321699e+00],\n",
            "       [-4.3995708e+01]], dtype=float32), array([26.246504], dtype=float32)]\n",
            "Training loss at step:  2000  is  51.305294\n",
            "[array([[-1.9008747e+01],\n",
            "       [ 3.7088486e+01],\n",
            "       [-1.6690411e+01],\n",
            "       [ 1.2523685e+00],\n",
            "       [ 7.2750926e-02],\n",
            "       [ 1.3894207e+01],\n",
            "       [-1.9070899e+00],\n",
            "       [-7.8102794e+00],\n",
            "       [ 8.3235235e+00],\n",
            "       [-1.6626528e+01],\n",
            "       [-1.6803713e+01],\n",
            "       [ 5.5968833e+00],\n",
            "       [-8.2248474e+01]], dtype=float32), array([32.26793], dtype=float32)]\n",
            "Training loss at step:  3000  is  48.32422\n",
            "[array([[ -27.111725  ],\n",
            "       [  36.23828   ],\n",
            "       [ -21.738054  ],\n",
            "       [   1.8654612 ],\n",
            "       [   0.11958864],\n",
            "       [  19.782158  ],\n",
            "       [   2.0461009 ],\n",
            "       [ -12.687583  ],\n",
            "       [  12.295185  ],\n",
            "       [ -18.5789    ],\n",
            "       [ -25.304295  ],\n",
            "       [   3.773983  ],\n",
            "       [-117.134544  ]], dtype=float32), array([35.45275], dtype=float32)]\n",
            "Training loss at step:  4000  is  45.853127\n",
            "[array([[ -34.405453  ],\n",
            "       [  34.947235  ],\n",
            "       [ -25.892702  ],\n",
            "       [   2.4681563 ],\n",
            "       [   0.17036463],\n",
            "       [  25.3905    ],\n",
            "       [   5.299135  ],\n",
            "       [ -17.453363  ],\n",
            "       [  15.964782  ],\n",
            "       [ -19.731422  ],\n",
            "       [ -33.496998  ],\n",
            "       [   2.610437  ],\n",
            "       [-148.9005    ]], dtype=float32), array([37.65205], dtype=float32)]\n",
            "Training loss at step:  5000  is  43.796032\n",
            "[array([[ -40.949997  ],\n",
            "       [  33.716927  ],\n",
            "       [ -29.281578  ],\n",
            "       [   3.0615172 ],\n",
            "       [   0.22603393],\n",
            "       [  30.77741   ],\n",
            "       [   8.187882  ],\n",
            "       [ -22.083378  ],\n",
            "       [  19.350927  ],\n",
            "       [ -20.587439  ],\n",
            "       [ -41.345314  ],\n",
            "       [   1.7126176 ],\n",
            "       [-177.79532   ]], dtype=float32), array([39.427067], dtype=float32)]\n",
            "Training loss at step:  6000  is  42.07985\n",
            "[array([[ -46.814827  ],\n",
            "       [  32.623898  ],\n",
            "       [ -32.002846  ],\n",
            "       [   3.6461954 ],\n",
            "       [   0.28642815],\n",
            "       [  35.973274  ],\n",
            "       [  10.796128  ],\n",
            "       [ -26.576195  ],\n",
            "       [  22.477905  ],\n",
            "       [ -21.31077   ],\n",
            "       [ -48.852467  ],\n",
            "       [   0.9533755 ],\n",
            "       [-204.07106   ]], dtype=float32), array([40.970097], dtype=float32)]\n",
            "Training loss at step:  7000  is  40.645\n",
            "[array([[ -52.06757   ],\n",
            "       [  31.662191  ],\n",
            "       [ -34.140625  ],\n",
            "       [   4.222728  ],\n",
            "       [   0.35110715],\n",
            "       [  40.999287  ],\n",
            "       [  13.151298  ],\n",
            "       [ -30.93619   ],\n",
            "       [  25.368404  ],\n",
            "       [ -21.96086   ],\n",
            "       [ -56.034     ],\n",
            "       [   0.28491712],\n",
            "       [-227.96361   ]], dtype=float32), array([42.357613], dtype=float32)]\n",
            "Training loss at step:  8000  is  39.442574\n",
            "[array([[ -56.770866  ],\n",
            "       [  30.81426   ],\n",
            "       [ -35.769012  ],\n",
            "       [   4.791605  ],\n",
            "       [   0.4195939 ],\n",
            "       [  45.872543  ],\n",
            "       [  15.272112  ],\n",
            "       [ -35.16923   ],\n",
            "       [  28.04254   ],\n",
            "       [ -22.562178  ],\n",
            "       [ -62.908836  ],\n",
            "       [  -0.31438574],\n",
            "       [-249.68903   ]], dtype=float32), array([43.625553], dtype=float32)]\n",
            "Training loss at step:  9000  is  38.4323\n",
            "[array([[ -60.981686  ],\n",
            "       [  30.064486  ],\n",
            "       [ -36.953804  ],\n",
            "       [   5.353282  ],\n",
            "       [   0.49143672],\n",
            "       [  50.607903  ],\n",
            "       [  17.176954  ],\n",
            "       [ -39.28138   ],\n",
            "       [  30.518236  ],\n",
            "       [ -23.126102  ],\n",
            "       [ -69.496315  ],\n",
            "       [  -0.8564313 ],\n",
            "       [-269.44366   ]], dtype=float32), array([44.79382], dtype=float32)]\n",
            "Training loss at step:  10000  is  37.581047\n",
            "[array([[ -64.75153   ],\n",
            "       [  29.400267  ],\n",
            "       [ -37.753494  ],\n",
            "       [   5.9081874 ],\n",
            "       [   0.56622183],\n",
            "       [  55.218536  ],\n",
            "       [  18.884247  ],\n",
            "       [ -43.278614  ],\n",
            "       [  32.811592  ],\n",
            "       [ -23.658699  ],\n",
            "       [ -75.814964  ],\n",
            "       [  -1.349001  ],\n",
            "       [-287.4061    ]], dtype=float32), array([45.875366], dtype=float32)]\n",
            "Training loss at step:  11000  is  36.861526\n",
            "[array([[ -68.12671  ],\n",
            "       [  28.811428 ],\n",
            "       [ -38.22011  ],\n",
            "       [   6.4567227],\n",
            "       [   0.6435753],\n",
            "       [  59.716255 ],\n",
            "       [  20.411835 ],\n",
            "       [ -47.166588 ],\n",
            "       [  34.937195 ],\n",
            "       [ -24.163591 ],\n",
            "       [ -81.882225 ],\n",
            "       [  -1.7978271],\n",
            "       [-303.73843  ]], dtype=float32), array([46.879547], dtype=float32)]\n",
            "Training loss at step:  12000  is  36.251244\n",
            "[array([[ -71.148895 ],\n",
            "       [  28.28942  ],\n",
            "       [ -38.39997  ],\n",
            "       [   6.9992585],\n",
            "       [   0.7231615],\n",
            "       [  64.11172  ],\n",
            "       [  21.776447 ],\n",
            "       [ -50.950653 ],\n",
            "       [  36.908302 ],\n",
            "       [ -24.64316  ],\n",
            "       [ -87.7142   ],\n",
            "       [  -2.2074738],\n",
            "       [-318.58774  ]], dtype=float32), array([47.81378], dtype=float32)]\n",
            "Training loss at step:  13000  is  35.73165\n",
            "[array([[ -73.85542   ],\n",
            "       [  27.826849  ],\n",
            "       [ -38.334183  ],\n",
            "       [   7.536138  ],\n",
            "       [   0.80467945],\n",
            "       [  68.41453   ],\n",
            "       [  22.993576  ],\n",
            "       [ -54.6359    ],\n",
            "       [  38.73698   ],\n",
            "       [ -25.099295  ],\n",
            "       [ -93.32594   ],\n",
            "       [  -2.581857  ],\n",
            "       [-332.0877    ]], dtype=float32), array([48.68438], dtype=float32)]\n",
            "Training loss at step:  14000  is  35.28744\n",
            "[array([[ -76.279816 ],\n",
            "       [  27.417234 ],\n",
            "       [ -38.05917  ],\n",
            "       [   8.067682 ],\n",
            "       [   0.8878585],\n",
            "       [  72.63329  ],\n",
            "       [  24.077343 ],\n",
            "       [ -58.227066 ],\n",
            "       [  40.434277 ],\n",
            "       [ -25.533556 ],\n",
            "       [ -98.73119  ],\n",
            "       [  -2.924387 ],\n",
            "       [-344.35983  ]], dtype=float32), array([49.496864], dtype=float32)]\n",
            "Training loss at step:  15000  is  34.90597\n",
            "[array([[ -78.45214   ],\n",
            "       [  27.05485   ],\n",
            "       [ -37.60727   ],\n",
            "       [   8.594201  ],\n",
            "       [   0.97245663],\n",
            "       [  76.77593   ],\n",
            "       [  25.040644  ],\n",
            "       [ -61.72864   ],\n",
            "       [  42.01027   ],\n",
            "       [ -25.947285  ],\n",
            "       [-103.94262   ],\n",
            "       [  -3.2380908 ],\n",
            "       [-355.51443   ]], dtype=float32), array([50.256115], dtype=float32)]\n",
            "Training loss at step:  16000  is  34.57682\n",
            "[array([[ -80.39929  ],\n",
            "       [  26.73456  ],\n",
            "       [ -37.00707  ],\n",
            "       [   9.115938 ],\n",
            "       [   1.0582579],\n",
            "       [  80.84949  ],\n",
            "       [  25.895145 ],\n",
            "       [ -65.14486  ],\n",
            "       [  43.474228 ],\n",
            "       [ -26.341732 ],\n",
            "       [-108.97197  ],\n",
            "       [  -3.5256948],\n",
            "       [-365.65158  ]], dtype=float32), array([50.966576], dtype=float32)]\n",
            "Training loss at step:  17000  is  34.291348\n",
            "[array([[ -82.14537  ],\n",
            "       [  26.45179  ],\n",
            "       [ -36.283752 ],\n",
            "       [   9.633177 ],\n",
            "       [   1.1450704],\n",
            "       [  84.86033  ],\n",
            "       [  26.651398 ],\n",
            "       [ -68.479614 ],\n",
            "       [  44.834618 ],\n",
            "       [ -26.717926 ],\n",
            "       [-113.83005  ],\n",
            "       [  -3.7895842],\n",
            "       [-374.86224  ]], dtype=float32), array([51.63213], dtype=float32)]\n",
            "Training loss at step:  18000  is  34.042404\n",
            "[array([[ -83.712    ],\n",
            "       [  26.20242  ],\n",
            "       [ -35.45964  ],\n",
            "       [  10.146171 ],\n",
            "       [   1.2327194],\n",
            "       [  88.81436  ],\n",
            "       [  27.319006 ],\n",
            "       [ -71.73671  ],\n",
            "       [  46.09917  ],\n",
            "       [ -27.07692  ],\n",
            "       [-118.52683  ],\n",
            "       [  -4.0319757],\n",
            "       [-383.22922  ]], dtype=float32), array([52.256416], dtype=float32)]\n",
            "Training loss at step:  19000  is  33.82408\n",
            "[array([[ -85.11846  ],\n",
            "       [  25.982782 ],\n",
            "       [ -34.554276 ],\n",
            "       [  10.65513  ],\n",
            "       [   1.3210528],\n",
            "       [  92.71678  ],\n",
            "       [  27.906647 ],\n",
            "       [ -74.919716 ],\n",
            "       [  47.274967 ],\n",
            "       [ -27.419666 ],\n",
            "       [-123.07143  ],\n",
            "       [  -4.2548513],\n",
            "       [-390.82767  ]], dtype=float32), array([52.84273], dtype=float32)]\n",
            "Training loss at step:  20000  is  33.631454\n",
            "[array([[ -86.382065 ],\n",
            "       [  25.789549 ],\n",
            "       [ -33.584858 ],\n",
            "       [  11.160247 ],\n",
            "       [   1.4099346],\n",
            "       [  96.572365 ],\n",
            "       [  28.422113 ],\n",
            "       [ -78.03177  ],\n",
            "       [  48.368587 ],\n",
            "       [ -27.74702  ],\n",
            "       [-127.4724   ],\n",
            "       [  -4.4599886],\n",
            "       [-397.72617  ]], dtype=float32), array([53.394016], dtype=float32)]\n",
            "Training loss at step:  21000  is  33.460476\n",
            "[array([[ -87.51834  ],\n",
            "       [  25.619759 ],\n",
            "       [ -32.566463 ],\n",
            "       [  11.661728 ],\n",
            "       [   1.499245 ],\n",
            "       [ 100.38509  ],\n",
            "       [  28.87253  ],\n",
            "       [ -81.07608  ],\n",
            "       [  49.385944 ],\n",
            "       [ -28.059809 ],\n",
            "       [-131.7376   ],\n",
            "       [  -4.6489987],\n",
            "       [-403.98663  ]], dtype=float32), array([53.913006], dtype=float32)]\n",
            "Training loss at step:  22000  is  33.30774\n",
            "[array([[ -88.54108  ],\n",
            "       [  25.470797 ],\n",
            "       [ -31.512209 ],\n",
            "       [  12.159801 ],\n",
            "       [   1.5888752],\n",
            "       [ 104.159256 ],\n",
            "       [  29.264303 ],\n",
            "       [ -84.055664 ],\n",
            "       [  50.332607 ],\n",
            "       [ -28.3588   ],\n",
            "       [-135.87415  ],\n",
            "       [  -4.8233533],\n",
            "       [-409.66565  ]], dtype=float32), array([54.402157], dtype=float32)]\n",
            "Training loss at step:  23000  is  33.17045\n",
            "[array([[ -89.46265  ],\n",
            "       [  25.34022  ],\n",
            "       [ -30.433546 ],\n",
            "       [  12.65453  ],\n",
            "       [   1.6787181],\n",
            "       [ 107.898056 ],\n",
            "       [  29.60322  ],\n",
            "       [ -86.97322  ],\n",
            "       [  51.213573 ],\n",
            "       [ -28.64475  ],\n",
            "       [-139.88904  ],\n",
            "       [  -4.9843965],\n",
            "       [-414.81497  ]], dtype=float32), array([54.863785], dtype=float32)]\n",
            "Training loss at step:  24000  is  33.04624\n",
            "[array([[ -90.29413  ],\n",
            "       [  25.22594  ],\n",
            "       [ -29.340435 ],\n",
            "       [  13.146165 ],\n",
            "       [   1.7687103],\n",
            "       [ 111.60484  ],\n",
            "       [  29.89452  ],\n",
            "       [ -89.83127  ],\n",
            "       [  52.033497 ],\n",
            "       [ -28.9182   ],\n",
            "       [-143.78821  ],\n",
            "       [  -5.1332555],\n",
            "       [-419.48096  ]], dtype=float32), array([55.299797], dtype=float32)]\n",
            "Training loss at step:  25000  is  32.93317\n",
            "[array([[ -91.04529  ],\n",
            "       [  25.126057 ],\n",
            "       [ -28.241425 ],\n",
            "       [  13.634831 ],\n",
            "       [   1.8587134],\n",
            "       [ 115.28242  ],\n",
            "       [  30.142967 ],\n",
            "       [ -92.632576 ],\n",
            "       [  52.79664  ],\n",
            "       [ -29.179848 ],\n",
            "       [-147.57755  ],\n",
            "       [  -5.27104  ],\n",
            "       [-423.7062   ]], dtype=float32), array([55.71213], dtype=float32)]\n",
            "Training loss at step:  26000  is  32.8296\n",
            "[array([[ -91.72497  ],\n",
            "       [  25.038836 ],\n",
            "       [ -27.143963 ],\n",
            "       [  14.120662 ],\n",
            "       [   1.9487165],\n",
            "       [ 118.93326  ],\n",
            "       [  30.352852 ],\n",
            "       [ -95.37922  ],\n",
            "       [  53.506973 ],\n",
            "       [ -29.430403 ],\n",
            "       [-151.26244  ],\n",
            "       [  -5.398808 ],\n",
            "       [-427.52942  ]], dtype=float32), array([56.102646], dtype=float32)]\n",
            "Training loss at step:  27000  is  32.734158\n",
            "[array([[ -92.34106  ],\n",
            "       [  24.962772 ],\n",
            "       [ -26.05411  ],\n",
            "       [  14.603801 ],\n",
            "       [   2.0386682],\n",
            "       [ 122.559814 ],\n",
            "       [  30.527933 ],\n",
            "       [ -98.07338  ],\n",
            "       [  54.16804  ],\n",
            "       [ -29.67028  ],\n",
            "       [-154.84784  ],\n",
            "       [  -5.517371 ],\n",
            "       [-430.9863   ]], dtype=float32), array([56.47277], dtype=float32)]\n",
            "Training loss at step:  28000  is  32.645702\n",
            "[array([[ -92.90061  ],\n",
            "       [  24.896465 ],\n",
            "       [ -24.977415 ],\n",
            "       [  15.084374 ],\n",
            "       [   2.128552 ],\n",
            "       [ 126.1641   ],\n",
            "       [  30.671791 ],\n",
            "       [-100.717415 ],\n",
            "       [  54.783268 ],\n",
            "       [ -29.900084 ],\n",
            "       [-158.33841  ],\n",
            "       [  -5.6275826],\n",
            "       [-434.10825  ]], dtype=float32), array([56.824017], dtype=float32)]\n",
            "Training loss at step:  29000  is  32.56326\n",
            "[array([[ -93.409904 ],\n",
            "       [  24.838808 ],\n",
            "       [ -23.91836  ],\n",
            "       [  15.562427 ],\n",
            "       [   2.2182484],\n",
            "       [ 129.74846  ],\n",
            "       [  30.787567 ],\n",
            "       [-103.31305  ],\n",
            "       [  55.35564  ],\n",
            "       [ -30.120203 ],\n",
            "       [-161.73836  ],\n",
            "       [  -5.7301073],\n",
            "       [-436.92517  ]], dtype=float32), array([57.15759], dtype=float32)]\n",
            "Training loss at step:  30000  is  32.48603\n",
            "[array([[ -93.87433  ],\n",
            "       [  24.788582 ],\n",
            "       [ -22.880722 ],\n",
            "       [  16.03818  ],\n",
            "       [   2.307764 ],\n",
            "       [ 133.31346  ],\n",
            "       [  30.878174 ],\n",
            "       [-105.862305 ],\n",
            "       [  55.888077 ],\n",
            "       [ -30.331064 ],\n",
            "       [-165.05208  ],\n",
            "       [  -5.8255587],\n",
            "       [-439.46295  ]], dtype=float32), array([57.47464], dtype=float32)]\n",
            "Training loss at step:  31000  is  32.413326\n",
            "[array([[ -94.299    ],\n",
            "       [  24.744987 ],\n",
            "       [ -21.86763  ],\n",
            "       [  16.511719 ],\n",
            "       [   2.3970497],\n",
            "       [ 136.8617   ],\n",
            "       [  30.946146 ],\n",
            "       [-108.367004 ],\n",
            "       [  56.383118 ],\n",
            "       [ -30.533215 ],\n",
            "       [-168.28256  ],\n",
            "       [  -5.9146404],\n",
            "       [-441.74646  ]], dtype=float32), array([57.77639], dtype=float32)]\n",
            "Training loss at step:  32000  is  32.34456\n",
            "[array([[ -94.68822  ],\n",
            "       [  24.706997 ],\n",
            "       [ -20.881628 ],\n",
            "       [  16.983105 ],\n",
            "       [   2.4860766],\n",
            "       [ 140.39427  ],\n",
            "       [  30.993778 ],\n",
            "       [-110.82851  ],\n",
            "       [  56.843285 ],\n",
            "       [ -30.727007 ],\n",
            "       [-171.434    ],\n",
            "       [  -5.9978447],\n",
            "       [-443.7979   ]], dtype=float32), array([58.063824], dtype=float32)]\n",
            "Training loss at step:  33000  is  32.279255\n",
            "[array([[ -95.04598  ],\n",
            "       [  24.674044 ],\n",
            "       [ -19.924776 ],\n",
            "       [  17.452383 ],\n",
            "       [   2.5748281],\n",
            "       [ 143.91258  ],\n",
            "       [  31.023214 ],\n",
            "       [-113.248856 ],\n",
            "       [  57.270767 ],\n",
            "       [ -30.912872 ],\n",
            "       [-174.5095   ],\n",
            "       [  -6.075705 ],\n",
            "       [-445.63654  ]], dtype=float32), array([58.337887], dtype=float32)]\n",
            "Training loss at step:  34000  is  32.216984\n",
            "[array([[ -95.37603  ],\n",
            "       [  24.645256 ],\n",
            "       [ -18.998642 ],\n",
            "       [  17.91962  ],\n",
            "       [   2.6632402],\n",
            "       [ 147.41812  ],\n",
            "       [  31.036367 ],\n",
            "       [-115.629234 ],\n",
            "       [  57.66769  ],\n",
            "       [ -31.091036 ],\n",
            "       [-177.51237  ],\n",
            "       [  -6.1485586],\n",
            "       [-447.28156  ]], dtype=float32), array([58.59928], dtype=float32)]\n",
            "Training loss at step:  35000  is  32.157387\n",
            "[array([[ -95.68097  ],\n",
            "       [  24.620028 ],\n",
            "       [ -18.104443 ],\n",
            "       [  18.384989 ],\n",
            "       [   2.7513375],\n",
            "       [ 150.91238  ],\n",
            "       [  31.034874 ],\n",
            "       [-117.97121  ],\n",
            "       [  58.03593  ],\n",
            "       [ -31.262032 ],\n",
            "       [-180.4445   ],\n",
            "       [  -6.216966 ],\n",
            "       [-448.74976  ]], dtype=float32), array([58.849003], dtype=float32)]\n",
            "Training loss at step:  36000  is  32.1002\n",
            "[array([[ -95.963585],\n",
            "       [  24.598042],\n",
            "       [ -17.243042],\n",
            "       [  18.848475],\n",
            "       [   2.839096],\n",
            "       [ 154.39175 ],\n",
            "       [  31.020357],\n",
            "       [-120.2759  ],\n",
            "       [  58.37732 ],\n",
            "       [ -31.42601 ],\n",
            "       [-183.30986 ],\n",
            "       [  -6.281111],\n",
            "       [-450.0556  ]], dtype=float32), array([59.08759], dtype=float32)]\n",
            "Training loss at step:  37000  is  32.045128\n",
            "[array([[ -96.22672  ],\n",
            "       [  24.578527 ],\n",
            "       [ -16.41499  ],\n",
            "       [  19.310146 ],\n",
            "       [   2.9264863],\n",
            "       [ 157.86234  ],\n",
            "       [  30.99421  ],\n",
            "       [-122.54488  ],\n",
            "       [  58.69352  ],\n",
            "       [ -31.583391 ],\n",
            "       [-186.11023  ],\n",
            "       [  -6.3414574],\n",
            "       [-451.2137   ]], dtype=float32), array([59.3158], dtype=float32)]\n",
            "Training loss at step:  38000  is  31.991932\n",
            "[array([[ -96.472176 ],\n",
            "       [  24.561352 ],\n",
            "       [ -15.620611 ],\n",
            "       [  19.770115 ],\n",
            "       [   3.0135124],\n",
            "       [ 161.32608  ],\n",
            "       [  30.957647 ],\n",
            "       [-124.77944  ],\n",
            "       [  58.98605  ],\n",
            "       [ -31.734379 ],\n",
            "       [-188.84799  ],\n",
            "       [  -6.398279 ],\n",
            "       [-452.23672  ]], dtype=float32), array([59.534153], dtype=float32)]\n",
            "Training loss at step:  39000  is  31.940483\n",
            "[array([[ -96.70217  ],\n",
            "       [  24.546074 ],\n",
            "       [ -14.859981 ],\n",
            "       [  20.228476 ],\n",
            "       [   3.1001666],\n",
            "       [ 164.77518  ],\n",
            "       [  30.911837 ],\n",
            "       [-126.98054  ],\n",
            "       [  59.25633  ],\n",
            "       [ -31.879246 ],\n",
            "       [-191.52562  ],\n",
            "       [  -6.451763 ],\n",
            "       [-453.1359   ]], dtype=float32), array([59.743248], dtype=float32)]\n",
            "Training loss at step:  40000  is  31.890547\n",
            "[array([[ -96.91866  ],\n",
            "       [  24.532572 ],\n",
            "       [ -14.132997 ],\n",
            "       [  20.685326 ],\n",
            "       [   3.1864157],\n",
            "       [ 168.22115  ],\n",
            "       [  30.857872 ],\n",
            "       [-129.14923  ],\n",
            "       [  59.50578  ],\n",
            "       [ -32.018223 ],\n",
            "       [-194.14476  ],\n",
            "       [  -6.5022607],\n",
            "       [-453.921    ]], dtype=float32), array([59.94348], dtype=float32)]\n",
            "Training loss at step:  41000  is  31.84204\n",
            "[array([[ -97.121765 ],\n",
            "       [  24.520124 ],\n",
            "       [ -13.439421 ],\n",
            "       [  21.140768 ],\n",
            "       [   3.2722898],\n",
            "       [ 171.65437  ],\n",
            "       [  30.79649  ],\n",
            "       [-131.28674  ],\n",
            "       [  59.735577 ],\n",
            "       [ -32.151695 ],\n",
            "       [-196.70808  ],\n",
            "       [  -6.549932 ],\n",
            "       [-454.60376  ]], dtype=float32), array([60.135582], dtype=float32)]\n",
            "Training loss at step:  42000  is  31.794767\n",
            "[array([[ -97.314835 ],\n",
            "       [  24.508604 ],\n",
            "       [ -12.778805 ],\n",
            "       [  21.594717 ],\n",
            "       [   3.3577611],\n",
            "       [ 175.08556  ],\n",
            "       [  30.728683 ],\n",
            "       [-133.39412  ],\n",
            "       [  59.946907 ],\n",
            "       [ -32.27972  ],\n",
            "       [-199.21732  ],\n",
            "       [  -6.595032 ],\n",
            "       [-455.19165  ]], dtype=float32), array([60.31975], dtype=float32)]\n",
            "Training loss at step:  43000  is  31.748703\n",
            "[array([[ -97.49721  ],\n",
            "       [  24.497892 ],\n",
            "       [ -12.150676 ],\n",
            "       [  22.04696  ],\n",
            "       [   3.4428215],\n",
            "       [ 178.50352  ],\n",
            "       [  30.65511  ],\n",
            "       [-135.4723   ],\n",
            "       [  60.140938 ],\n",
            "       [ -32.40268  ],\n",
            "       [-201.67397  ],\n",
            "       [  -6.6377063],\n",
            "       [-455.693    ]], dtype=float32), array([60.496605], dtype=float32)]\n",
            "Training loss at step:  44000  is  31.703669\n",
            "[array([[ -97.67074  ],\n",
            "       [  24.48812  ],\n",
            "       [ -11.554378 ],\n",
            "       [  22.498032 ],\n",
            "       [   3.5274901],\n",
            "       [ 181.9215   ],\n",
            "       [  30.576712 ],\n",
            "       [-137.52246  ],\n",
            "       [  60.31862  ],\n",
            "       [ -32.520523 ],\n",
            "       [-204.07957  ],\n",
            "       [  -6.6780944],\n",
            "       [-456.11615  ]], dtype=float32), array([60.666157], dtype=float32)]\n",
            "Training loss at step:  45000  is  31.659657\n",
            "[array([[ -97.83649  ],\n",
            "       [  24.478582 ],\n",
            "       [ -10.989202 ],\n",
            "       [  22.948057 ],\n",
            "       [   3.6117582],\n",
            "       [ 185.32692  ],\n",
            "       [  30.493774 ],\n",
            "       [-139.54446  ],\n",
            "       [  60.480816 ],\n",
            "       [ -32.633686 ],\n",
            "       [-206.43631  ],\n",
            "       [  -6.716388 ],\n",
            "       [-456.4659   ]], dtype=float32), array([60.82912], dtype=float32)]\n",
            "Training loss at step:  46000  is  31.61654\n",
            "[array([[ -97.99531  ],\n",
            "       [  24.469046 ],\n",
            "       [ -10.454458 ],\n",
            "       [  23.396284 ],\n",
            "       [   3.6955974],\n",
            "       [ 188.72963  ],\n",
            "       [  30.406809 ],\n",
            "       [-141.53943  ],\n",
            "       [  60.62844  ],\n",
            "       [ -32.74229  ],\n",
            "       [-208.74529  ],\n",
            "       [  -6.7527523],\n",
            "       [-456.7493   ]], dtype=float32), array([60.985683], dtype=float32)]\n",
            "Training loss at step:  47000  is  31.574253\n",
            "[array([[ -98.147896],\n",
            "       [  24.459713],\n",
            "       [  -9.949295],\n",
            "       [  23.843494],\n",
            "       [   3.779042],\n",
            "       [ 192.12943 ],\n",
            "       [  30.316313],\n",
            "       [-143.5093  ],\n",
            "       [  60.762577],\n",
            "       [ -32.846462],\n",
            "       [-211.00795 ],\n",
            "       [  -6.787303],\n",
            "       [-456.97293 ]], dtype=float32), array([61.136143], dtype=float32)]\n",
            "Training loss at step:  48000  is  31.532799\n",
            "[array([[ -98.29322  ],\n",
            "       [  24.450956 ],\n",
            "       [  -9.472851 ],\n",
            "       [  24.289814 ],\n",
            "       [   3.862093 ],\n",
            "       [ 195.51688  ],\n",
            "       [  30.223122 ],\n",
            "       [-145.45416  ],\n",
            "       [  60.883648 ],\n",
            "       [ -32.94638  ],\n",
            "       [-213.22568  ],\n",
            "       [  -6.8200345],\n",
            "       [-457.14053  ]], dtype=float32), array([61.28071], dtype=float32)]\n",
            "Training loss at step:  49000  is  31.492052\n",
            "[array([[ -98.433945 ],\n",
            "       [  24.44208  ],\n",
            "       [  -9.024218 ],\n",
            "       [  24.734356 ],\n",
            "       [   3.944717 ],\n",
            "       [ 198.90433  ],\n",
            "       [  30.127365 ],\n",
            "       [-147.37358  ],\n",
            "       [  60.992676 ],\n",
            "       [ -33.042328 ],\n",
            "       [-215.39986  ],\n",
            "       [  -6.8512864],\n",
            "       [-457.25623  ]], dtype=float32), array([61.41976], dtype=float32)]\n",
            "Training loss at step:  50000  is  31.451971\n",
            "[array([[ -98.57127  ],\n",
            "       [  24.432922 ],\n",
            "       [  -8.6025   ],\n",
            "       [  25.178291 ],\n",
            "       [   4.0269275],\n",
            "       [ 202.28856  ],\n",
            "       [  30.029184 ],\n",
            "       [-149.27112  ],\n",
            "       [  61.090263 ],\n",
            "       [ -33.134113 ],\n",
            "       [-217.532    ],\n",
            "       [  -6.880928 ],\n",
            "       [-457.32846  ]], dtype=float32), array([61.553383], dtype=float32)]\n",
            "Training loss at step:  51000  is  31.412603\n",
            "[array([[ -98.70137 ],\n",
            "       [  24.423937],\n",
            "       [  -8.206779],\n",
            "       [  25.620796],\n",
            "       [   4.108763],\n",
            "       [ 205.66075 ],\n",
            "       [  29.929497],\n",
            "       [-151.14326 ],\n",
            "       [  61.17716 ],\n",
            "       [ -33.222336],\n",
            "       [-219.62256 ],\n",
            "       [  -6.909149],\n",
            "       [-457.35544 ]], dtype=float32), array([61.681957], dtype=float32)]\n",
            "Training loss at step:  52000  is  31.37381\n",
            "[array([[ -98.83052  ],\n",
            "       [  24.41469  ],\n",
            "       [  -7.8361387],\n",
            "       [  26.062384 ],\n",
            "       [   4.1902137],\n",
            "       [ 209.03294  ],\n",
            "       [  29.828014 ],\n",
            "       [-152.99509  ],\n",
            "       [  61.253727 ],\n",
            "       [ -33.30689  ],\n",
            "       [-221.67288  ],\n",
            "       [  -6.936125 ],\n",
            "       [-457.3438   ]], dtype=float32), array([61.805687], dtype=float32)]\n",
            "Training loss at step:  53000  is  31.335564\n",
            "[array([[ -98.95259  ],\n",
            "       [  24.405188 ],\n",
            "       [  -7.4896264],\n",
            "       [  26.502981 ],\n",
            "       [   4.271276 ],\n",
            "       [ 212.40514  ],\n",
            "       [  29.725254 ],\n",
            "       [-154.82333  ],\n",
            "       [  61.32087  ],\n",
            "       [ -33.38785  ],\n",
            "       [-223.68497  ],\n",
            "       [  -6.9617195],\n",
            "       [-457.29755  ]], dtype=float32), array([61.92455], dtype=float32)]\n",
            "Training loss at step:  54000  is  31.29793\n",
            "[array([[ -99.07466  ],\n",
            "       [  24.39565  ],\n",
            "       [  -7.1663156],\n",
            "       [  26.9424   ],\n",
            "       [   4.3518667],\n",
            "       [ 215.76385  ],\n",
            "       [  29.621304 ],\n",
            "       [-156.63124  ],\n",
            "       [  61.378788 ],\n",
            "       [ -33.465366 ],\n",
            "       [-225.65807  ],\n",
            "       [  -6.986122 ],\n",
            "       [-457.21872  ]], dtype=float32), array([62.03895], dtype=float32)]\n",
            "Training loss at step:  55000  is  31.260794\n",
            "[array([[ -99.190056 ],\n",
            "       [  24.386114 ],\n",
            "       [  -6.865261 ],\n",
            "       [  27.38109  ],\n",
            "       [   4.432083 ],\n",
            "       [ 219.12079  ],\n",
            "       [  29.516777 ],\n",
            "       [-158.41933  ],\n",
            "       [  61.42832  ],\n",
            "       [ -33.539776 ],\n",
            "       [-227.59488  ],\n",
            "       [  -7.0094056],\n",
            "       [-457.11008  ]], dtype=float32), array([62.149063], dtype=float32)]\n",
            "Training loss at step:  56000  is  31.224133\n",
            "[array([[ -99.3045   ],\n",
            "       [  24.375982 ],\n",
            "       [  -6.5855827],\n",
            "       [  27.818527 ],\n",
            "       [   4.5119295],\n",
            "       [ 222.47772  ],\n",
            "       [  29.411499 ],\n",
            "       [-160.18523  ],\n",
            "       [  61.469826 ],\n",
            "       [ -33.6109   ],\n",
            "       [-229.49571  ],\n",
            "       [  -7.031621 ],\n",
            "       [-456.9748   ]], dtype=float32), array([62.25488], dtype=float32)]\n",
            "Training loss at step:  57000  is  31.18794\n",
            "[array([[ -99.41667  ],\n",
            "       [  24.365091 ],\n",
            "       [  -6.3263946],\n",
            "       [  28.25531  ],\n",
            "       [   4.591408 ],\n",
            "       [ 225.8311   ],\n",
            "       [  29.305428 ],\n",
            "       [-161.93251  ],\n",
            "       [  61.503784 ],\n",
            "       [ -33.67882  ],\n",
            "       [-231.36067  ],\n",
            "       [  -7.052724 ],\n",
            "       [-456.8168   ]], dtype=float32), array([62.35656], dtype=float32)]\n",
            "Training loss at step:  58000  is  31.152239\n",
            "[array([[ -99.52348  ],\n",
            "       [  24.354244 ],\n",
            "       [  -6.086847 ],\n",
            "       [  28.690966 ],\n",
            "       [   4.670527 ],\n",
            "       [ 229.17278  ],\n",
            "       [  29.198833 ],\n",
            "       [-163.66136  ],\n",
            "       [  61.53068  ],\n",
            "       [ -33.74396  ],\n",
            "       [-233.19185  ],\n",
            "       [  -7.0727634],\n",
            "       [-456.6337   ]], dtype=float32), array([62.45446], dtype=float32)]\n",
            "Training loss at step:  59000  is  31.116947\n",
            "[array([[ -99.630295 ],\n",
            "       [  24.343248 ],\n",
            "       [  -5.8660502],\n",
            "       [  29.125841 ],\n",
            "       [   4.749205 ],\n",
            "       [ 232.51445  ],\n",
            "       [  29.092306 ],\n",
            "       [-165.3711   ],\n",
            "       [  61.55105  ],\n",
            "       [ -33.806355 ],\n",
            "       [-234.98976  ],\n",
            "       [  -7.092009 ],\n",
            "       [-456.42737  ]], dtype=float32), array([62.54862], dtype=float32)]\n",
            "Training loss at step:  60000  is  31.082043\n",
            "[array([[ -99.73497  ],\n",
            "       [  24.331804 ],\n",
            "       [  -5.663141 ],\n",
            "       [  29.559925 ],\n",
            "       [   4.8274894],\n",
            "       [ 235.85612  ],\n",
            "       [  28.985764 ],\n",
            "       [-167.0615   ],\n",
            "       [  61.564754 ],\n",
            "       [ -33.86578  ],\n",
            "       [-236.75514  ],\n",
            "       [  -7.1103916],\n",
            "       [-456.20966  ]], dtype=float32), array([62.639126], dtype=float32)]\n",
            "Training loss at step:  61000  is  31.047543\n",
            "[array([[ -99.83415  ],\n",
            "       [  24.32036  ],\n",
            "       [  -5.4773955],\n",
            "       [  29.992893 ],\n",
            "       [   4.9054227],\n",
            "       [ 239.19283  ],\n",
            "       [  28.878834 ],\n",
            "       [-168.73448  ],\n",
            "       [  61.572895 ],\n",
            "       [ -33.922585 ],\n",
            "       [-238.48859  ],\n",
            "       [  -7.127684 ],\n",
            "       [-455.9655   ]], dtype=float32), array([62.725815], dtype=float32)]\n",
            "Training loss at step:  62000  is  31.01347\n",
            "[array([[ -99.933334 ],\n",
            "       [  24.30842  ],\n",
            "       [  -5.3078084],\n",
            "       [  30.425634 ],\n",
            "       [   4.9830236],\n",
            "       [ 242.51924  ],\n",
            "       [  28.772476 ],\n",
            "       [-170.39038  ],\n",
            "       [  61.575165 ],\n",
            "       [ -33.976776 ],\n",
            "       [-240.1908   ],\n",
            "       [  -7.1442475],\n",
            "       [-455.7149   ]], dtype=float32), array([62.80936], dtype=float32)]\n",
            "Training loss at step:  63000  is  30.97973\n",
            "[array([[-100.03252  ],\n",
            "       [  24.296335 ],\n",
            "       [  -5.153885 ],\n",
            "       [  30.856695 ],\n",
            "       [   5.0602713],\n",
            "       [ 245.84566  ],\n",
            "       [  28.665665 ],\n",
            "       [-172.0294   ],\n",
            "       [  61.572598 ],\n",
            "       [ -34.028538 ],\n",
            "       [-241.86241  ],\n",
            "       [  -7.160028 ],\n",
            "       [-455.44025  ]], dtype=float32), array([62.88947], dtype=float32)]\n",
            "Training loss at step:  64000  is  30.946331\n",
            "[array([[-100.12578  ],\n",
            "       [  24.283161 ],\n",
            "       [  -5.0146985],\n",
            "       [  31.287756 ],\n",
            "       [   5.1370544],\n",
            "       [ 249.17207  ],\n",
            "       [  28.559467 ],\n",
            "       [-173.65189  ],\n",
            "       [  61.56501  ],\n",
            "       [ -34.077866 ],\n",
            "       [-243.50429  ],\n",
            "       [  -7.1750827],\n",
            "       [-455.1656   ]], dtype=float32), array([62.966587], dtype=float32)]\n",
            "Training loss at step:  65000  is  30.913267\n",
            "[array([[-100.21733  ],\n",
            "       [  24.270525 ],\n",
            "       [  -4.8895874],\n",
            "       [  31.71748  ],\n",
            "       [   5.213511 ],\n",
            "       [ 252.49452  ],\n",
            "       [  28.45308  ],\n",
            "       [-175.25806  ],\n",
            "       [  61.552605 ],\n",
            "       [ -34.12488  ],\n",
            "       [-245.11696  ],\n",
            "       [  -7.1892853],\n",
            "       [-454.8646   ]], dtype=float32), array([63.04026], dtype=float32)]\n",
            "Training loss at step:  66000  is  30.880583\n",
            "[array([[-100.30888  ],\n",
            "       [  24.257359 ],\n",
            "       [  -4.777958 ],\n",
            "       [  32.14598  ],\n",
            "       [   5.289645 ],\n",
            "       [ 255.80568  ],\n",
            "       [  28.347153 ],\n",
            "       [-176.84827  ],\n",
            "       [  61.536037 ],\n",
            "       [ -34.16951  ],\n",
            "       [-246.7014   ],\n",
            "       [  -7.2027183],\n",
            "       [-454.55942  ]], dtype=float32), array([63.111023], dtype=float32)]\n",
            "Training loss at step:  67000  is  30.848145\n",
            "[array([[-100.40044  ],\n",
            "       [  24.244007 ],\n",
            "       [  -4.678867 ],\n",
            "       [  32.573227 ],\n",
            "       [   5.3654623],\n",
            "       [ 259.12527  ],\n",
            "       [  28.242342 ],\n",
            "       [-178.4228   ],\n",
            "       [  61.515575 ],\n",
            "       [ -34.21177  ],\n",
            "       [-248.25824  ],\n",
            "       [  -7.215666 ],\n",
            "       [-454.25424  ]], dtype=float32), array([63.178867], dtype=float32)]\n",
            "Training loss at step:  68000  is  30.816137\n",
            "[array([[-100.4847   ],\n",
            "       [  24.230656 ],\n",
            "       [  -4.5918317],\n",
            "       [  33.000473 ],\n",
            "       [   5.440811 ],\n",
            "       [ 262.42117  ],\n",
            "       [  28.137602 ],\n",
            "       [-179.98203  ],\n",
            "       [  61.491375 ],\n",
            "       [ -34.252426 ],\n",
            "       [-249.78833  ],\n",
            "       [  -7.2277164],\n",
            "       [-453.924    ]], dtype=float32), array([63.243965], dtype=float32)]\n",
            "Training loss at step:  69000  is  30.784405\n",
            "[array([[-100.56863  ],\n",
            "       [  24.217304 ],\n",
            "       [  -4.516452 ],\n",
            "       [  33.42772  ],\n",
            "       [   5.5158463],\n",
            "       [ 265.71707  ],\n",
            "       [  28.032639 ],\n",
            "       [-181.52615  ],\n",
            "       [  61.463825 ],\n",
            "       [ -34.290714 ],\n",
            "       [-251.29135  ],\n",
            "       [  -7.239072 ],\n",
            "       [-453.58832  ]], dtype=float32), array([63.306145], dtype=float32)]\n",
            "Training loss at step:  70000  is  30.752945\n",
            "[array([[-100.65255  ],\n",
            "       [  24.203506 ],\n",
            "       [  -4.4518194],\n",
            "       [  33.854965 ],\n",
            "       [   5.5905876],\n",
            "       [ 269.01297  ],\n",
            "       [  27.928938 ],\n",
            "       [-183.05565  ],\n",
            "       [  61.43327  ],\n",
            "       [ -34.327076 ],\n",
            "       [-252.76772  ],\n",
            "       [  -7.249992 ],\n",
            "       [-453.25262  ]], dtype=float32), array([63.365807], dtype=float32)]\n",
            "Training loss at step:  71000  is  30.721737\n",
            "[array([[-100.73647  ],\n",
            "       [  24.188766 ],\n",
            "       [  -4.397355 ],\n",
            "       [  34.281956 ],\n",
            "       [   5.664974 ],\n",
            "       [ 272.30887  ],\n",
            "       [  27.825893 ],\n",
            "       [-184.57079  ],\n",
            "       [  61.39894  ],\n",
            "       [ -34.361397 ],\n",
            "       [-254.21957  ],\n",
            "       [  -7.2604055],\n",
            "       [-452.91693  ]], dtype=float32), array([63.422997], dtype=float32)]\n",
            "Training loss at step:  72000  is  30.690788\n",
            "[array([[-100.815   ],\n",
            "       [  24.17429 ],\n",
            "       [  -4.352418],\n",
            "       [  34.705387],\n",
            "       [   5.738951],\n",
            "       [ 275.60477 ],\n",
            "       [  27.72375 ],\n",
            "       [-186.07191 ],\n",
            "       [  61.361946],\n",
            "       [ -34.393974],\n",
            "       [-255.64606 ],\n",
            "       [  -7.270171],\n",
            "       [-452.57053 ]], dtype=float32), array([63.47745], dtype=float32)]\n",
            "Training loss at step:  73000  is  30.660053\n",
            "[array([[-100.8913   ],\n",
            "       [  24.160173 ],\n",
            "       [  -4.316884 ],\n",
            "       [  35.12882  ],\n",
            "       [   5.8126354],\n",
            "       [ 278.90067  ],\n",
            "       [  27.62076  ],\n",
            "       [-187.55939  ],\n",
            "       [  61.32311  ],\n",
            "       [ -34.42453  ],\n",
            "       [-257.0516   ],\n",
            "       [  -7.2790256],\n",
            "       [-452.2043   ]], dtype=float32), array([63.528957], dtype=float32)]\n",
            "Training loss at step:  74000  is  30.629576\n",
            "[array([[-100.96759  ],\n",
            "       [  24.14545  ],\n",
            "       [  -4.2901545],\n",
            "       [  35.55225  ],\n",
            "       [   5.8860407],\n",
            "       [ 282.19656  ],\n",
            "       [  27.518238 ],\n",
            "       [-189.03363  ],\n",
            "       [  61.281147 ],\n",
            "       [ -34.453083 ],\n",
            "       [-258.42688  ],\n",
            "       [  -7.287387 ],\n",
            "       [-451.8381   ]], dtype=float32), array([63.57783], dtype=float32)]\n",
            "Training loss at step:  75000  is  30.599318\n",
            "[array([[-101.043884 ],\n",
            "       [  24.130566 ],\n",
            "       [  -4.2716465],\n",
            "       [  35.97568  ],\n",
            "       [   5.958997 ],\n",
            "       [ 285.49246  ],\n",
            "       [  27.41683  ],\n",
            "       [-190.49503  ],\n",
            "       [  61.2376   ],\n",
            "       [ -34.479813 ],\n",
            "       [-259.7807   ],\n",
            "       [  -7.295224 ],\n",
            "       [-451.4719   ]], dtype=float32), array([63.62433], dtype=float32)]\n",
            "Training loss at step:  76000  is  30.569445\n",
            "[array([[-101.1187   ],\n",
            "       [  24.115545 ],\n",
            "       [  -4.260855 ],\n",
            "       [  36.399113 ],\n",
            "       [   6.031654 ],\n",
            "       [ 288.76315  ],\n",
            "       [  27.31629  ],\n",
            "       [-191.9439   ],\n",
            "       [  61.191822 ],\n",
            "       [ -34.504986 ],\n",
            "       [-261.11404  ],\n",
            "       [  -7.3024364],\n",
            "       [-451.10568  ]], dtype=float32), array([63.668934], dtype=float32)]\n",
            "Training loss at step:  77000  is  30.53982\n",
            "[array([[-101.18736  ],\n",
            "       [  24.100386 ],\n",
            "       [  -4.2573075],\n",
            "       [  36.82212  ],\n",
            "       [   6.104055 ],\n",
            "       [ 292.02853  ],\n",
            "       [  27.216885 ],\n",
            "       [-193.37822  ],\n",
            "       [  61.144432 ],\n",
            "       [ -34.52871  ],\n",
            "       [-262.4263   ],\n",
            "       [  -7.30912  ],\n",
            "       [-450.73947  ]], dtype=float32), array([63.711437], dtype=float32)]\n",
            "Training loss at step:  78000  is  30.510426\n",
            "[array([[-101.25603  ],\n",
            "       [  24.085136 ],\n",
            "       [  -4.2604885],\n",
            "       [  37.241737 ],\n",
            "       [   6.1760573],\n",
            "       [ 295.2939   ],\n",
            "       [  27.118183 ],\n",
            "       [-194.79967  ],\n",
            "       [  61.09484  ],\n",
            "       [ -34.550957 ],\n",
            "       [-263.70963  ],\n",
            "       [  -7.3156066],\n",
            "       [-450.37326  ]], dtype=float32), array([63.75181], dtype=float32)]\n",
            "Training loss at step:  79000  is  30.481226\n",
            "[array([[-101.32469 ],\n",
            "       [  24.069878],\n",
            "       [  -4.269969],\n",
            "       [  37.661354],\n",
            "       [   6.247733],\n",
            "       [ 298.5593  ],\n",
            "       [  27.020681],\n",
            "       [-196.20938 ],\n",
            "       [  61.045223],\n",
            "       [ -34.5717  ],\n",
            "       [-264.9745  ],\n",
            "       [  -7.321621],\n",
            "       [-450.00705 ]], dtype=float32), array([63.790108], dtype=float32)]\n",
            "Training loss at step:  80000  is  30.452215\n",
            "[array([[-101.39336  ],\n",
            "       [  24.054619 ],\n",
            "       [  -4.285309 ],\n",
            "       [  38.08097  ],\n",
            "       [   6.319167 ],\n",
            "       [ 301.82468  ],\n",
            "       [  26.92377  ],\n",
            "       [-197.60786  ],\n",
            "       [  60.992016 ],\n",
            "       [ -34.590687 ],\n",
            "       [-266.22223  ],\n",
            "       [  -7.3270907],\n",
            "       [-449.64084  ]], dtype=float32), array([63.826267], dtype=float32)]\n",
            "Training loss at step:  81000  is  30.423409\n",
            "[array([[-101.45672 ],\n",
            "       [  24.039278],\n",
            "       [  -4.306134],\n",
            "       [  38.500587],\n",
            "       [   6.390216],\n",
            "       [ 305.09006 ],\n",
            "       [  26.82784 ],\n",
            "       [-198.9955  ],\n",
            "       [  60.93861 ],\n",
            "       [ -34.608227],\n",
            "       [-267.44293 ],\n",
            "       [  -7.332082],\n",
            "       [-449.27463 ]], dtype=float32), array([63.8601], dtype=float32)]\n",
            "Training loss at step:  82000  is  30.394785\n",
            "[array([[-101.51775  ],\n",
            "       [  24.023767 ],\n",
            "       [  -4.3322906],\n",
            "       [  38.920204 ],\n",
            "       [   6.460933 ],\n",
            "       [ 308.35544  ],\n",
            "       [  26.731485 ],\n",
            "       [-200.36879  ],\n",
            "       [  60.885204 ],\n",
            "       [ -34.62438  ],\n",
            "       [-268.64432  ],\n",
            "       [  -7.3363857],\n",
            "       [-448.89066  ]], dtype=float32), array([63.89153], dtype=float32)]\n",
            "Training loss at step:  83000  is  30.366314\n",
            "[array([[-101.57879  ],\n",
            "       [  24.008509 ],\n",
            "       [  -4.3637486],\n",
            "       [  39.33982  ],\n",
            "       [   6.5314045],\n",
            "       [ 311.62082  ],\n",
            "       [  26.634544 ],\n",
            "       [-201.73073  ],\n",
            "       [  60.83056  ],\n",
            "       [ -34.63885  ],\n",
            "       [-269.83176  ],\n",
            "       [  -7.3399234],\n",
            "       [-448.49753  ]], dtype=float32), array([63.92071], dtype=float32)]\n",
            "Training loss at step:  84000  is  30.338161\n",
            "[array([[-101.639824 ],\n",
            "       [  23.99325  ],\n",
            "       [  -4.4000936],\n",
            "       [  39.75734  ],\n",
            "       [   6.6014996],\n",
            "       [ 314.86768  ],\n",
            "       [  26.5385   ],\n",
            "       [-203.0828   ],\n",
            "       [  60.77334  ],\n",
            "       [ -34.651867 ],\n",
            "       [-270.99142  ],\n",
            "       [  -7.343125 ],\n",
            "       [-448.10736  ]], dtype=float32), array([63.94799], dtype=float32)]\n",
            "Training loss at step:  85000  is  30.310251\n",
            "[array([[-101.70086  ],\n",
            "       [  23.977991 ],\n",
            "       [  -4.440972 ],\n",
            "       [  40.17314  ],\n",
            "       [   6.671265 ],\n",
            "       [ 318.10254  ],\n",
            "       [  26.443241 ],\n",
            "       [-204.42542  ],\n",
            "       [  60.716118 ],\n",
            "       [ -34.663937 ],\n",
            "       [-272.13544  ],\n",
            "       [  -7.3460155],\n",
            "       [-447.7191   ]], dtype=float32), array([63.973984], dtype=float32)]\n",
            "Training loss at step:  86000  is  30.282516\n",
            "[array([[-101.75676 ],\n",
            "       [  23.962732],\n",
            "       [  -4.486009],\n",
            "       [  40.588943],\n",
            "       [   6.740811],\n",
            "       [ 321.3374  ],\n",
            "       [  26.34896 ],\n",
            "       [-205.75293 ],\n",
            "       [  60.658897],\n",
            "       [ -34.674747],\n",
            "       [-273.2646  ],\n",
            "       [  -7.348448],\n",
            "       [-447.3333  ]], dtype=float32), array([63.998184], dtype=float32)]\n",
            "Training loss at step:  87000  is  30.254961\n",
            "[array([[-101.810165 ],\n",
            "       [  23.947474 ],\n",
            "       [  -4.534925 ],\n",
            "       [  41.004745 ],\n",
            "       [   6.8099523],\n",
            "       [ 324.57227  ],\n",
            "       [  26.25572  ],\n",
            "       [-207.07133  ],\n",
            "       [  60.601677 ],\n",
            "       [ -34.68441  ],\n",
            "       [-274.36646  ],\n",
            "       [  -7.350623 ],\n",
            "       [-446.94955  ]], dtype=float32), array([64.02043], dtype=float32)]\n",
            "Training loss at step:  88000  is  30.227547\n",
            "[array([[-101.86357  ],\n",
            "       [  23.932215 ],\n",
            "       [  -4.587354 ],\n",
            "       [  41.420547 ],\n",
            "       [   6.878813 ],\n",
            "       [ 327.80713  ],\n",
            "       [  26.163214 ],\n",
            "       [-208.38123  ],\n",
            "       [  60.544456 ],\n",
            "       [ -34.692463 ],\n",
            "       [-275.45837  ],\n",
            "       [  -7.3519945],\n",
            "       [-446.566    ]], dtype=float32), array([64.04063], dtype=float32)]\n",
            "Training loss at step:  89000  is  30.200304\n",
            "[array([[-101.91698  ],\n",
            "       [  23.916956 ],\n",
            "       [  -4.643064 ],\n",
            "       [  41.83635  ],\n",
            "       [   6.9474673],\n",
            "       [ 331.042    ],\n",
            "       [  26.071377 ],\n",
            "       [-209.67822  ],\n",
            "       [  60.487236 ],\n",
            "       [ -34.699814 ],\n",
            "       [-276.5265   ],\n",
            "       [  -7.353549 ],\n",
            "       [-446.1843   ]], dtype=float32), array([64.05961], dtype=float32)]\n",
            "Training loss at step:  90000  is  30.17321\n",
            "[array([[-101.97038  ],\n",
            "       [  23.901697 ],\n",
            "       [  -4.701791 ],\n",
            "       [  42.25215  ],\n",
            "       [   7.015657 ],\n",
            "       [ 334.27686  ],\n",
            "       [  25.980299 ],\n",
            "       [-210.96498  ],\n",
            "       [  60.430016 ],\n",
            "       [ -34.705254 ],\n",
            "       [-277.5798   ],\n",
            "       [  -7.3541865],\n",
            "       [-445.8029   ]], dtype=float32), array([64.076035], dtype=float32)]\n",
            "Training loss at step:  91000  is  30.146267\n",
            "[array([[-102.02026  ],\n",
            "       [  23.886438 ],\n",
            "       [  -4.763302 ],\n",
            "       [  42.66671  ],\n",
            "       [   7.0836353],\n",
            "       [ 337.51172  ],\n",
            "       [  25.8897   ],\n",
            "       [-212.24432  ],\n",
            "       [  60.372795 ],\n",
            "       [ -34.709934 ],\n",
            "       [-278.6174   ],\n",
            "       [  -7.3546352],\n",
            "       [-445.42432  ]], dtype=float32), array([64.09129], dtype=float32)]\n",
            "Training loss at step:  92000  is  30.119585\n",
            "[array([[-102.06604 ],\n",
            "       [  23.870943],\n",
            "       [  -4.827285],\n",
            "       [  43.078697],\n",
            "       [   7.151346],\n",
            "       [ 340.73044 ],\n",
            "       [  25.800396],\n",
            "       [-213.5108  ],\n",
            "       [  60.315575],\n",
            "       [ -34.712925],\n",
            "       [-279.63348 ],\n",
            "       [  -7.354202],\n",
            "       [-445.04974 ]], dtype=float32), array([64.10415], dtype=float32)]\n",
            "Training loss at step:  93000  is  30.09312\n",
            "[array([[-102.11182  ],\n",
            "       [  23.855684 ],\n",
            "       [  -4.893665 ],\n",
            "       [  43.490685 ],\n",
            "       [   7.2186594],\n",
            "       [ 343.93478  ],\n",
            "       [  25.712019 ],\n",
            "       [-214.76778  ],\n",
            "       [  60.258354 ],\n",
            "       [ -34.71494  ],\n",
            "       [-280.64056  ],\n",
            "       [  -7.3532734],\n",
            "       [-444.67633  ]], dtype=float32), array([64.11574], dtype=float32)]\n",
            "Training loss at step:  94000  is  30.06682\n",
            "[array([[-102.15759  ],\n",
            "       [  23.840425 ],\n",
            "       [  -4.962236 ],\n",
            "       [  43.90267  ],\n",
            "       [   7.285796 ],\n",
            "       [ 347.13913  ],\n",
            "       [  25.624083 ],\n",
            "       [-216.01834  ],\n",
            "       [  60.201134 ],\n",
            "       [ -34.7172   ],\n",
            "       [-281.62085  ],\n",
            "       [  -7.3531604],\n",
            "       [-444.30685  ]], dtype=float32), array([64.12718], dtype=float32)]\n",
            "Training loss at step:  95000  is  30.040638\n",
            "[array([[-102.20337  ],\n",
            "       [  23.825167 ],\n",
            "       [  -5.0326734],\n",
            "       [  44.31466  ],\n",
            "       [   7.3525534],\n",
            "       [ 350.34348  ],\n",
            "       [  25.536665 ],\n",
            "       [-217.2543   ],\n",
            "       [  60.143913 ],\n",
            "       [ -34.718277 ],\n",
            "       [-282.5974   ],\n",
            "       [  -7.352449 ],\n",
            "       [-443.93576  ]], dtype=float32), array([64.13711], dtype=float32)]\n",
            "Training loss at step:  96000  is  30.01461\n",
            "[array([[-102.248344 ],\n",
            "       [  23.809908 ],\n",
            "       [  -5.1049147],\n",
            "       [  44.726646 ],\n",
            "       [   7.419039 ],\n",
            "       [ 353.54782  ],\n",
            "       [  25.449879 ],\n",
            "       [-218.48376  ],\n",
            "       [  60.086693 ],\n",
            "       [ -34.71786  ],\n",
            "       [-283.54434  ],\n",
            "       [  -7.3513374],\n",
            "       [-443.56848  ]], dtype=float32), array([64.14475], dtype=float32)]\n",
            "Training loss at step:  97000  is  29.98869\n",
            "[array([[-102.28649 ],\n",
            "       [  23.79465 ],\n",
            "       [  -5.178727],\n",
            "       [  45.138634],\n",
            "       [   7.485319],\n",
            "       [ 356.75217 ],\n",
            "       [  25.363924],\n",
            "       [-219.70447 ],\n",
            "       [  60.029472],\n",
            "       [ -34.716736],\n",
            "       [-284.49033 ],\n",
            "       [  -7.34965 ],\n",
            "       [-443.2014  ]], dtype=float32), array([64.15134], dtype=float32)]\n",
            "Training loss at step:  98000  is  29.962921\n",
            "[array([[-102.32464  ],\n",
            "       [  23.779543 ],\n",
            "       [  -5.2540164],\n",
            "       [  45.55062  ],\n",
            "       [   7.5511584],\n",
            "       [ 359.9565   ],\n",
            "       [  25.27828  ],\n",
            "       [-220.91333  ],\n",
            "       [  59.97225  ],\n",
            "       [ -34.7138   ],\n",
            "       [-285.4059   ],\n",
            "       [  -7.347396 ],\n",
            "       [-442.83517  ]], dtype=float32), array([64.1552], dtype=float32)]\n",
            "Training loss at step:  99000  is  29.937248\n",
            "[array([[-102.362785 ],\n",
            "       [  23.764673 ],\n",
            "       [  -5.3306613],\n",
            "       [  45.960766 ],\n",
            "       [   7.61683  ],\n",
            "       [ 363.16086  ],\n",
            "       [  25.193256 ],\n",
            "       [-222.11754  ],\n",
            "       [  59.917072 ],\n",
            "       [ -34.710682 ],\n",
            "       [-286.32144  ],\n",
            "       [  -7.345035 ],\n",
            "       [-442.46896  ]], dtype=float32), array([64.158745], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSkxDtoDTTdz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dc492a9-3c10-46bb-a1b5-c6213c674747"
      },
      "source": [
        "#Summary is a TensorFlow op that creates protocol buffers containing summarized data\n",
        "\n",
        "training_loss = tf.summary.scalar('train_loss',loss)\n",
        "training_loss"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'train_loss:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltR_pDqzYN1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = '/content/log/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHyHobwrY4fH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "60a2c6f6-c170-4c04-b746-f9cdb187d706"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  training_epochs=1000\n",
        "  #training and saving the graph\n",
        "  saver = tf.train.Saver()\n",
        "  writer = tf.summary.FileWriter(log_dir,graph=tf.get_default_graph())\n",
        "  #a python class that writes data to disk for Tensorboard\n",
        "  for epoch in range(training_epochs):\n",
        "\n",
        "    train_model,train_loss,loss_log = sess.run([train_op,loss,training_loss],feed_dict={x:features,y_:prices})\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print('Training loss at step', epoch, 'is', train_loss)\n",
        "      print('Log loss at step',epoch, 'is',loss_log)\n",
        "\n",
        "    saver.save(sess,log_dir + '/' + 'boston.ckpt')\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step 0 is 592.1469\n",
            "Log loss at step 0 is b'\\n\\x11\\n\\ntrain_loss\\x15g\\t\\x14D'\n",
            "Training loss at step 100 is 62.029503\n",
            "Log loss at step 100 is b'\\n\\x11\\n\\ntrain_loss\\x156\\x1exB'\n",
            "Training loss at step 200 is 60.355377\n",
            "Log loss at step 200 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xe8kqB'\n",
            "Training loss at step 300 is 59.182304\n",
            "Log loss at step 300 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xae\\xbalB'\n",
            "Training loss at step 400 is 58.296078\n",
            "Log loss at step 400 is b'\\n\\x11\\n\\ntrain_loss\\x15//iB'\n",
            "Training loss at step 500 is 57.5795\n",
            "Log loss at step 500 is b'\\n\\x11\\n\\ntrain_loss\\x15hQfB'\n",
            "Training loss at step 600 is 56.967342\n",
            "Log loss at step 600 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x8f\\xdecB'\n",
            "Training loss at step 700 is 56.422527\n",
            "Log loss at step 700 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xab\\xb0aB'\n",
            "Training loss at step 800 is 55.923412\n",
            "Log loss at step 800 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x93\\xb1_B'\n",
            "Training loss at step 900 is 55.456974\n",
            "Log loss at step 900 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xf1\\xd3]B'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lIskMb_aunc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}